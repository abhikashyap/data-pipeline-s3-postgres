{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b4270cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"check\").getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54941e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+------------+--------------------+------------+--------------------+-------+---------+------+------+-----+-----+-----+-----+\n",
      "|  PORTFOLIOS|ADS TYP|ACCOUNT NAME|           CAMPAIGNS| ad_group_id|             KEYWORD|   DATE|MATCH TYP|IMPRSN|CLICKS|UNITS|  CPC|SALES|SPEND|\n",
      "+------------+-------+------------+--------------------+------------+--------------------+-------+---------+------+------+-----+-----+-----+-----+\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Ast...|M4FUE3IXDGOD|best chimney for ...|07-2025|    EXACT|   331|     7|    0| 33.0|    0|232.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|  PCA-Spotlight-Cube|9W76JZTQH4AN|       slant chimney|07-2025|    EXACT|   189|     5|    0| 42.0|    0|208.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Ast...|M4FUE3IXDGOD|pigeon chimney fo...|07-2025|    EXACT|   435|     5|    0| 91.0|    0|457.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|  PCA-Spotlight-Cube|9W76JZTQH4AN|kitchen chimney a...|07-2025|    EXACT|    41|     1|    0| 45.0|    0| 45.0|\n",
      "|Chimney 60cm|    PCA|   BeyondNxt|FK-Asteria-60cm-P...|QVTO1N7L4WKG|kitchen chimney a...|07-2025|    EXACT|     1|     0|    0|  0.0|    0|  0.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Ast...|M4FUE3IXDGOD|        chimney 75cm|07-2025|    EXACT|    52|     0|    0|  0.0|    0| 36.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Hob...|0TH3EIV3QKEY|gas stoves automa...|07-2025|    EXACT|    69|     5|    0|  4.0|    0| 21.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Hob...|0TH3EIV3QKEY|    hob top 3 burner|07-2025|    EXACT|    13|     1|    0|  4.0|    0|  4.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Ast...|M4FUE3IXDGOD|chimney for kitch...|07-2025|    EXACT|   175|     2|    0| 92.0|    0|184.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|  PCA-Spotlight-Cube|9W76JZTQH4AN|kitchen chimney a...|07-2025|    EXACT|   124|     1|    0|167.0|    0|167.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Ast...|M4FUE3IXDGOD|chimney for kitch...|07-2025|    EXACT|   329|     4|    0| 58.0|    0|230.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Hob...|0TH3EIV3QKEY|best gas stove 4 ...|07-2025|    EXACT|     9|     0|    0|  0.0|    0| 14.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|  PCA-Spotlight-Cube|9W76JZTQH4AN|small chimney for...|07-2025|    EXACT|   177|     6|    0| 32.0|    0|195.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Ast...|M4FUE3IXDGOD|kutchina kitchen ...|07-2025|    EXACT|   379|     4|    0| 99.0|    0|398.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Hob...|0TH3EIV3QKEY|automatic hob gas...|07-2025|    EXACT|    15|     0|    0|  0.0|    0|  5.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Hob...|0TH3EIV3QKEY|gas stove with timer|07-2025|    EXACT|    13|     3|    0|  1.0|    0|  4.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Hob...|0TH3EIV3QKEY|         kitchen hob|07-2025|    EXACT|    17|     0|    0|  0.0|    0| 26.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Ast...|M4FUE3IXDGOD|kitchen chimney 7...|07-2025|    EXACT|    16|     0|    0|  0.0|    0| 11.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Hob...|0TH3EIV3QKEY|auto ignition gas...|07-2025|    EXACT|    47|     3|    0| 24.0|    0| 71.0|\n",
      "| Chimney-HOB|    PCA|   BeyondNxt|PCA-Spotlight-Ast...|M4FUE3IXDGOD|  chimney auto clean|07-2025|    EXACT|    73|     0|    0|  0.0|    0| 51.0|\n",
      "+------------+-------+------------+--------------------+------------+--------------------+-------+---------+------+------+-----+-----+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame  # or: from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.sql import functions as F, types as T\n",
    "from main.utility.logging_config import logger\n",
    "df: DataFrame = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"inferSchema\", True)\n",
    "    .option(\"header\", True)\n",
    "    .load(\"../fk.csv\")\n",
    ")\n",
    "df.show()\n",
    "logger.log(level=10,msg=\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c21c2da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA_HOME: /opt/java/openjdk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/23 00:12:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/08/23 00:12:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark: 3.5.1\n",
      "STS: {'UserId': 'AROAZI2LGOPW3CVN6PGSU:i-0399e8193fe8f80bc', 'Account': '637423481837', 'Arn': 'arn:aws:sts::637423481837:assumed-role/server/i-0399e8193fe8f80bc', 'ResponseMetadata': {'RequestId': '88cc4601-989b-4729-b785-36256254abb3', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '88cc4601-989b-4729-b785-36256254abb3', 'x-amz-sts-extended-request-id': 'MTp1cy1lYXN0LTE6MTc1NTkwNzk2OTA1NTpHOmVjb013SlhV', 'content-type': 'text/xml', 'content-length': '451', 'date': 'Sat, 23 Aug 2025 00:12:49 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/23 00:12:51 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|brand_name|\n",
      "+----------+\n",
      "|     3bros|\n",
      "|      aadi|\n",
      "|      aayu|\n",
      "|      acer|\n",
      "|  achintya|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"JAVA_HOME:\", os.environ.get(\"JAVA_HOME\"))\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"check\").getOrCreate()\n",
    "print(\"Spark:\", spark.version)\n",
    "\n",
    "import boto3\n",
    "print(\"STS:\", boto3.client(\"sts\").get_caller_identity())\n",
    "\n",
    "df = spark.read.option(\"header\", True).option(\"inferSchema\", True)\\\n",
    "       .csv(\"s3a://mkdv1/brands.csv\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c04a974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PostgreSQL JDBC present ✅\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Should not raise:\n",
    "spark.sparkContext._jvm.java.lang.Class.forName(\"org.postgresql.Driver\")\n",
    "print(\"PostgreSQL JDBC present ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9dabc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------------------------------------------------------------------------------------------------------+\n",
      "|ok |server_version                                                                                                     |\n",
      "+---+-------------------------------------------------------------------------------------------------------------------+\n",
      "|1  |PostgreSQL 17.2 (Debian 17.2-1.pgdg120+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 12.2.0-14) 12.2.0, 64-bit|\n",
      "+---+-------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "ip='13.200.16.231'\n",
    "db='livedb'\n",
    "password='Techblooprint123'\n",
    "user=\"blooprint\"\n",
    "\n",
    "URL  = os.getenv(\"PG_JDBC_URL\", f\"jdbc:postgresql://{ip}:5433/{db}\")\n",
    "USER = os.getenv(\"PG_USER\", user)\n",
    "PWD  = os.getenv(\"PG_PASSWORD\", password)\n",
    "\n",
    "probe = (spark.read.format(\"jdbc\")\n",
    "         .option(\"url\", URL)\n",
    "         .option(\"user\", USER)\n",
    "         .option(\"password\", PWD)\n",
    "         .option(\"driver\", \"org.postgresql.Driver\")\n",
    "         .option(\"dbtable\", \"(select 1 as ok, version() as server_version) t\")\n",
    "         .load())\n",
    "\n",
    "probe.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b88fcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "testdf = spark.createDataFrame([Row(id=1, msg=\"hello\")])\n",
    "\n",
    "(testdf.write\n",
    " .format(\"jdbc\")\n",
    " .option(\"url\", URL)\n",
    " .option(\"user\", USER)\n",
    " .option(\"password\", PWD)\n",
    " .option(\"driver\", \"org.postgresql.Driver\")\n",
    " .option(\"dbtable\", \"public.spark_probe\")\n",
    " .mode(\"overwrite\")\n",
    " .save())\n",
    "\n",
    "print(\"Write OK ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3ed2ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "testdf = spark.createDataFrame([Row(id=1, msg=\"hello\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b16c33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, msg: string]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3348062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
